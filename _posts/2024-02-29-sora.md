---
title: "Sora: Technical Report 리뷰"
excerpt: "영상 생성 AI Sora의 기술 보고서를 간단히 리뷰합니다. "
toc: true
toc_sticky: false
---

![](https://velog.velcdn.com/images/yuhyeon0809/post/2d9beb9a-b8c7-4098-86a3-79b1883b7002/image.mp4)

지난 2월 15일, ChatGPT로 유명한 OpenAI에서 영상 생성 AI **Sora**를 공개했다.  

최대 1분 가량의 초고품질 영상을 생성하는 Text-to-Video 모델로, 공개 직후부터 많은 화제가 되었다.  
ChatGPT의 첫 등장이 그랬던 것처럼, 또 한 번의 큰 파장이 일어날 전망이다. 

[관련 기사](https://www.aitimes.com/news/articleView.html?idxno=157296)와 [영상](https://www.youtube.com/watch?v=KEoE-XD_SiY&t=1s)이 쏟아져 나올 정도로 많은 분야에서 Sora에 관심을 보이는 이유는 바로 생성물의 퀄리티에 있다.  
AI가 만든 영상이라고는 믿기지 않을 정도로 사실적이며, 높은 완성도를 자랑한다.  

<sub> 피식대학이 패러디한 Sora 영상 (개인적으로 재밌게 봐서 공유합니다🤣)</sub>
<iframe width="560" height="315" src="https://www.youtube.com/embed/s9WiifS8p0g?si=gVi9FTrENLJI2r6J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>  


---    


현재 OpenAI는 Sora에 대한 [기술 보고서(Technical Report)](https://openai.com/research/video-generation-models-as-world-simulators)만 공개한 상태다. ***<Video generation models as world simulators\>*** 라는 제목의 기술 보고서를 읽고 간단히 정리해 보았다.  

[![sora 웹페이지](https://velog.velcdn.com/images/yuhyeon0809/post/83a479cd-88ad-4157-a342-6ec781bac517/image.png)](https://openai.com/sora)
<center><sub> 이미지를 누르면 Sora 웹페이지로 연결됩니다 </sub></center>

## Introduction

Sora는 다른 영상 생성 모델과 마찬가지로, 생성 모델을 대규모 영상 데이터로 훈련시키는 연구에서 비롯되었다. 다양한 지속 시간, 종횡비, 해상도를 가진 영상 및 이미지 데이터로 Text-conditional Diffusion 모델을 훈련시켰다.  

주목할만한 점은 Transformer 아키텍처를 사용했다는 점이다. Diffusion Transformer 구조로 샘플 퀄리티와 더불어 다양한 영역으로의 확장이 가능하다는데, 자세한 내용은 뒤에서 다룰 예정이다.  

### OpenAI의 Largest Model, Sora

Sora는 대규모의 영상 및 이미지 데이터로 훈련되었기 때문에, 현재 <mark>OpenAI의 모델 중</mark> 규모가 가장 큰 것으로 소개된다. 특히나 Runway, Pika, Stable Video Diffusion 등 타 영상 생성 AI 모델과 비교했을 때 Sora는 후발 주자이지만, 압도적인 성능으로 기존 모델과의 비교를 무의미하게 만들었다.  

이전 연구(Recurrent Network, GAN, Autoregressive Transformer 등)에서 Visual Data의 일부(짧은 비디오, 고정 크기 비디오 등)에 초점을 맞춘 경우가 다수 있었던 문제를 참고해, Sora는 다음과 같은 것을 내세웠다. 

> **Sora가 내세운 것**
> - Visual Data에 대한 Generalist Model(범용 모델)
> - 다양한 지속 시간, 해상도, 종횡비를 아우르는 최대 1분 분량의 고화질 영상 생성  

> **본 기술 보고서(Technical Report)의 핵심**
> - 모든 유형의 Visual Data를 (대규모 훈련을 위한) 통일된 표현(패치)으로 변환하는 방법
> - Sora의 기능 및 한계에 대한 질적 평가
> - 모델 및 세부 구현 정보는 포함하지 않음  

---  

## Visual Data를 Patch로 변환하다

### 영감은 LLM으로부터  

ChatGPT를 개발한 LLM(대규모 언어 모델)의 명가 OpenAI 답게, Sora는 LLM으로부터 영감을 얻어 만들어졌다. 

연구진은 LLM 패러다임의 성공 요인을 다양한 양식의 텍스트(코드, 수식 등의 자연어)를 통합하는 **‘토큰’** 의 사용으로 보았고, '토큰' 역할을 하는 **'패치(Patches)'** 를 영상 생성 모델에 적용했다. 

### 패치란 무엇인가
Visual Data를 일정한 크기로 분할한 것을 나타내는 개념이다. 
![](https://velog.velcdn.com/images/yuhyeon0809/post/58686766-c0c6-4c40-9942-9174da33f503/image.png)


영상을 패치로 분할하는 과정은 크게 두 단계를 거친다.

1. 비디오를 낮은 차원의 Latent Space로 압축
2. 압축된 표현을 시공간(Spacetime) 패치로 분할

> **패치 기반 표현의 이점**
> - Visual Data를 **효과적**으로 표현할 수 있다. 
> - 다양한 해상도, 지속 시간, 종횡비를 가진 비디오/이미지 데이터에 대한 **확장성**이 뛰어나다. 
> - 추론 결과로 생성된 영상의 **크기를 제어**할 수 있다.  
> -> 적절한 크기의 그리드에 랜덤 초기화된 패치를 배열함으로써

---

## Diffusion Transformer  

Sora는 기본적으로 Diffusion 기반 모델이다. **노이즈 패치**(및 텍스트 프롬프트 같은 Conditioning 정보)가 입력되면, 원래의 **‘clean’ 패치**를 예측하도록 훈련된다.  

### 영상 생성 모델로 확장된 Diffusion Transformer

더 나아가, Sora는 Diffusion 기반에 Transformer 아키텍처를 적용한 **Diffusion Transformer** 구조다. 

















