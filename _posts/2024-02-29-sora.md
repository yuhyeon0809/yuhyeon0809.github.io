---
title: "Sora: Technical Report 리뷰"
excerpt: "영상 생성 AI Sora의 기술 보고서를 간단히 리뷰합니다. "
toc: true
---

![](https://velog.velcdn.com/images/yuhyeon0809/post/2d9beb9a-b8c7-4098-86a3-79b1883b7002/image.mp4)

지난 2월 15일, ChatGPT로 유명한 **OpenAI**에서 영상 생성 AI **Sora**를 공개했습니다. 
최대 1분 가량의 초고품질 영상을 생성하는 Text-to-Video 모델로, 공개 직후부터 많은 화제가 되었습니다.  

Sora가 기업, 언론, 연구계를 막론하고 많은 관심을 받은 이유는 바로 **생성물의 퀄리티**에 있습니다. AI가 만든 영상이라고는 믿기지 않을만큼 사실적이며, 높은 완성도를 자랑합니다. 🫢  

현재 OpenAI는 Sora에 대한 [기술 보고서(Technical Report)](https://openai.com/research/video-generation-models-as-world-simulators)만 공개한 상태인데요. ***<Video generation models as world simulators\>*** 라는 제목의 기술 보고서를 읽고 간단히 정리해 보았습니다. 


---
![](https://velog.velcdn.com/images/yuhyeon0809/post/83a479cd-88ad-4157-a342-6ec781bac517/image.png)


<center>  

[Sora](https://openai.com/sora)  

</center>

## Introduction
Sora를 개발한 OpenAI 사는 ChatGPT로 유명한 AI 기업입니다. 
언어 모델인 ChatGPT를 비롯해, 이미지 생성 모델인 DALL-E 시리즈를 만들어 냈지만 영상 생성 모델의 소식은 들려오지 않았죠.  

Runway, Pika, Stable Video Diffusion 등 다른 기업에서 먼저 영상 생성 AI를 내놓았고, 드디어 지난 2월 15일 OpenAI에서도 영상 생성 AI를 공개했습니다. 

#### OpenAI의 Largest 모델, Sora
Sora는 영상 생성 AI 분야의 후발 주자이지만, 압도적인 성능으로 기존 모델과의 비교를 무의미하게 만들었습니다. '할리우드의 종말'이라는 표현이 나올 정도로 영상 분야에 큰 파장을 일으키고 있습니다. 

이전 연구(Recurrent Network, GAN, Autoregressive Transformer 등)에서 Visual Data의 일부(짧은 비디오, 고정 크기 비디오 등)에 초점을 맞춘 경우가 다수 있었던 문제를 참고해 다음과 같은 것을 내세웠습니다. 


> **Sora가 내세운 것**
> - Visual Data에 대한 Generalist Model
> - 다양한 지속 시간, 해상도, 종횡비를 아우르는 최대 1분 분량의 고화질 영상 생성


> **본 기술 보고서(Technical Report)의 핵심**
> - 모든 유형의 Visual Data를 (대규모 훈련을 위한) 통일된 표현(패치)으로 변환하는 방법
> - Sora의 기능 및 한계에 대한 질적 평가
> - 모델 및 세부 구현 정보는 포함하지 않음



---

## Visual Data를 Patch로 변환
#### 영감은 LLM으로부터
ChatGPT를 개발한 LLM(대규모 언어 모델)의 명가답게, Sora는 LLM으로부터 영감을 얻어 만들어졌습니다. 연구진은 LLM 패러다임의 성공 요인을 다양한 양식의 텍스트(코드, 수식 등의 자연어)를 통합하는 **‘토큰’** 의 사용으로 보았고, '토큰' 역할을 하는 **'패치(Patches)'** 를 영상 생성 모델에 적용했습니다. 

#### 패치란 무엇인가
Visual Data를 일정한 크기로 분할한 것을 나타내는 개념입니다. 
![](https://velog.velcdn.com/images/yuhyeon0809/post/58686766-c0c6-4c40-9942-9174da33f503/image.png)


영상을 패치로 분할하는 과정은 크게 두 단계를 거칩니다.

1. 비디오를 낮은 차원의 Latent Space로 압축
2. 압축된 표현을 시공간(Spacetime) 패치로 분할

> **패치 기반 표현의 이점**
- Visual Data를 **효과적**으로 표현할 수 있다. 
- 다양한 해상도, 지속 시간, 종횡비를 가진 비디오/이미지 데이터에 대한 **확장성**이 뛰어나다. 
- 추론 결과로 생성된 영상의 **크기를 제어**할 수 있다. 
-> 적절한 크기의 그리드에 랜덤 초기화된 패치를 배열함으로써

---

## Diffusion Transformer  

Sora는 기본적으로 Diffusion 기반 모델입니다. **노이즈 패치**(및 텍스트 프롬프트 같은 Conditioning 정보)가 입력되면, 원래의 **‘clean’ 패치**를 예측하도록 훈련됩니다.  

#### 영상 생성 모델로 확장된 Diffusion Transformer

더 나아가, Sora는 Diffusion 기반에 Transformer 아키텍처를 적용한 **Diffusion Transformer** 구조입니다. 









  
 






