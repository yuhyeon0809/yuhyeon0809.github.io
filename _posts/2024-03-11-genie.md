---
title: "Genie: Generative Interactive Environments 리뷰"
excerpt: "구글 딥마인드의 Foundation World Model, Genie 논문을 리뷰합니다."

categories: 
  - paper-review
# tags: 
#   - [tag1, tag2]

permalink: /paper-review/genie/ 

toc: true
toc_sticky: true
---

<sub> https://arxiv.org/abs/2402.15391  
https://sites.google.com/view/genie-2024  
</sub>


<img width="776" alt="genie_main" src="https://github.com/yuhyeon0809/yuhyeon0809/assets/98225529/71f89e14-86a6-49b9-bb20-325d8aeb03b8">

## Intro

<!-- 간략한 소개 -->
지난 2월, Google Deepmind가 공개한 생성적 상호작용 환경 (Generative Interactive Environments) 모델, **Genie🧞** 입니다. Text-to-Image 모델로 생성한 이미지, 손으로 그린 스케치, 실제 사진을 입력으로 받아 액션 제어가 가능한 게임 세계(Playable Worlds)를 생성하는 모델입니다. 

<!-- 등장 배경 -->
지난 몇 년간 생성 AI의 엄청난 발전이 있었음에도, ChatGPT와 같은 언어 모델과 영상 생성 모델간의 사용자 상호작용 및 참여 수준의 격차는 여전히 존재합니다. 유저가 프롬프트를 입력하면 모델이 생성 결과를 출력하고, 그 결과를 바탕으로 유저가 또 다시 프롬프트를 입력하는 식의, 소위 '티키타카'라고 하는 상호작용이 생성 AI 사용에 있어 더욱 몰입감 있는 경험을 만들어내는 것도 사실입니다. 

*만일, 인터넷의 방대한 비디오 데이터가 주어진다면?*

새로운 이미지 및 비디오 생성 뿐만 아니라, 완전히 인터랙티브한 경험(Entire Interactive Experience)을 만들어낼 수 있지 않을까요? 이러한 맥락에서, 구글 딥마인드는 생성 AI의 새로운 패러다임, Generative Interactive Environments를 제안합니다. 하나의 텍스트/이미지 프롬프트로부터 인터랙티브한 '환경'을 생성하는 것이죠. 

<!-- 핵심 특징 -->

### 🧞Genie
- 11B 개의 파라미터로 Foundation Model의 특성을 가집니다. 
- 20만 시간이 넘는 인터넷 게임 영상 데이터셋으로 훈련되었습니다.  
  - (필터링을 거쳐 정제된 데이터셋은 약 3만 시간)
- 액션 레이블이 없는 Video-only 데이터로 훈련되었음에도, Latent Action Space(잠재 액션 공간)를 학습해 프레임 단위의 액션 제어가 가능합니다. (중요)

## Genie의 구조

<!-- 세 가지 컴포넌트 -->
Genie는 크게 3 가지의 핵심 컴포넌트로 구성되어 있습니다. 

- **Latent Action Model(LAM)**: 프레임과 프레임 사이의 Latent Action $a$를 학습합니다. 
- **Video Tokenizer**: Raw 비디오 프레임을 이산 토큰(Discrete Token) $z$로 변환합니다. 
- **Dynamics Model**: 이전 프레임들의 토큰과 Latent Action을 받아 다음 프레임을 예측합니다. 

### 0. ST-transformer

핵심 컴포넌트를 살펴보기에 앞서, 먼저 ST-transformer에 대해 알아야합니다. Genie의 모든 컴포넌트가 이 아키텍처를 채택했기 때문입니다. 

[ST-transformer](https://arxiv.org/pdf/2001.02908.pdf)는 Spatial-Temporal Transformer의 약자로, 공간적(Spatial) 정보와 시간적(Temporal) 정보를 함께 처리할 수 있는 트랜스포머 기반 모델입니다. Genie가 오리지널 ViT가 아닌 이 아키텍처를 사용한 이유이자 가장 큰 특징은 비디오 데이터의 연산에 있어 **메모리 효율적**이라는 점입니다.  




### 1. Latent Action Model(LAM)

### 2. Video Tokenizer

### 3. Dynamics Model

## Genie의 추론 과정

## 실험 결과

<!-- 데이터셋, Metric -->

### 확장 결과 (Scailing Results)

### 질적 결과 (Qualitative Results)

### Ablation Studies

## 결론 및 향후 연구